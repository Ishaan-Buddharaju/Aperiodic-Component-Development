Chi2Contingency
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20848,"status":"ok","timestamp":1686962803440,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"2Urp3jOQIPZU","outputId":"019773e5-4fdb-4b05-b729-f1b43cbfd23d"},"outputs":[],"source":["%pip install mne\n","%pip install matplotlib\n","%pip install pymatreader\n","%pip install scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6950,"status":"ok","timestamp":1686962815662,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"I8IYSjLfnE2a","outputId":"18360fe9-feca-4ab9-c8e8-34d88c241d40"},"outputs":[],"source":["%pip install FOOOF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5530,"status":"ok","timestamp":1686962821190,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"SdqqDQ_znLgQ","outputId":"2624c960-fcc3-441d-9c1c-40599a82760a"},"outputs":[],"source":["%pip install neurodsp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install python-dotenv"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"FuEv2adNIdH6"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv()\n","\n","import numpy as np\n","import matplotlib\n","import mne\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# the following import is required for matplotlib < 3.2:\n","from mpl_toolkits.mplot3d import Axes3D  # noqa\n","\n","from neurodsp.spectral import compute_spectrum, trim_spectrum\n","\n","\n","# Import NeuroDSP plotting functions\n","from neurodsp.plts import (plot_time_series, plot_power_spectra, plot_bursts, plot_lagged_coherence)\n","\n","from fooof import FOOOF\n","import os\n","import pandas as pd\n","import csv\n","\n","import scipy\n","from scipy import stats\n","from collections import Counter"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["load_dotenv('PipelineVariables.env')\n","EEG_Directory=os.getenv('EEG_Directory')\n","EEG_Results_Directory=os.getenv('EEG_Results_Directory')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ijhj11fh-8oL"},"source":["# **The Following functions are functions for pre-processing the data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd {EEG_Directory}"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1T-IXK1cJKht"},"outputs":[],"source":["def segment_channels(raw): ## segments the data into desired channels\n","  channels_to_keep = ['E1', 'E2', 'E3', 'E4', 'E8', 'E9', 'E10', 'E15', 'E16', 'E18', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E32', 'E33', 'E122', 'E123', 'E124']\n","  return raw.pick_channels(channels_to_keep)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"M_3CR4fk0FmY"},"outputs":[],"source":["def avgChannels(raw): ## averages channels into one evoked object of the data for the frontal lobe\n","  events = mne.find_events(raw, stim_channel = None)\n","  epochs = mne.Epochs(raw, events, event_id=None, tmin=0, tmax=10)\n","  evoked = epochs.average()\n","  return evoked"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Jl5Gbjxbzw_L"},"outputs":[],"source":["def computeFOOOF(raw):  ## FOOOF computations\n","  data, times = raw[:,:]\n","  freqs, powers = compute_spectrum(data[0], fs, method='welch', avg_type='median')\n","  freqs, powers = trim_spectrum(freqs, powers, [3, 28])\n","  return fm.report(freqs, powers, [3,28])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BuJuMwtmyytb"},"source":["# **These blocks create necessary global variables for preprocessing, set our working directory, creating the FOOOF report, renaming files, and creating the PANDAS dataframe**"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1rESsSvY6m6u"},"outputs":[],"source":["\n","groups=dict(frontal = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n","fs = 250"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CAJIMdagnj0F"},"outputs":[],"source":["#PANDAS Lists to be appended then made into Data frame\n","PersonalID = []\n","age = []\n","sex =[]\n","\n","Aper_exp = []\n","Aper_exp = []\n","variance = []\n","error = []\n","\n","ProcessedDataDict = {'ID': PersonalID, 'Age': age, 'Sex': sex,\n","'Aper_offset': Aper_offset, 'Aper_exp': Aper_exp, 'Variance': variance, 'Error': error}\n","\n","PeakID = []\n","PeakIndex = []\n","CenterFrequency = []\n","PeakWidth = []\n","BandWidth = []\n","\n","ProcessedPeaksDataDict = {'ID': PeakID, 'Age': age, 'Sex': sex, 'Peak_Number': PeakIndex , 'CF': CenterFrequency, 'PW': PeakWidth, 'BW': BandWidth}\n","\n","failedIDs = []\n","redundantIDs = []\n","otherError = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686962824809,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"vvwYeeJmtoZJ","outputId":"65e8076f-ac79-44db-dae8-f3317533bb06"},"outputs":[],"source":["%cd {EEG_Directory}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kCsP7CFhW4P1"},"source":["Completed so don't run once renamed"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3ErpbYdE9RMf"},"outputs":[],"source":["\n","# for filename in os.listdir():\n","#   if filename.endswith('.fdt'):\n","#     os.rename(filename, filename[::-1][22::][::-1] + '.fdt')  #renames the files\n","#   elif filename.endswith('.set'):\n","#     os.rename(filename, filename[::-1][22::][::-1] + '.set')\n","# print('successfully completed')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SAQwx0UzydDS"},"source":["# **Loop for preprocessing the files, creating FOOOF report, and saving the report to pandas.**"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"XNCcC72qIEs1"},"outputs":[],"source":["phenoDF = pd.read_csv('CorrectPhenotypesRaw.csv')  #phenotpypic data frame\n","phenoDF = phenoDF.set_index('EID')\n","\n","fm = FOOOF()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XhzTHOMIN_nb"},"source":["Cell runs the analysis and saves values to be made into data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JG2wEwcU-oJedBVUSPrkOaztNiZb9Lt_"},"executionInfo":{"elapsed":3862581,"status":"error","timestamp":1686968287161,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"taTCR2RYlIhm","outputId":"855740aa-01a7-4d55-a82c-ca2f2fbd3e40"},"outputs":[],"source":["for IDs, row in phenoDF.iterrows():\n","  if IDs not in PersonalID:\n","    try:\n","      raw = mne.io.read_raw_eeglab(input_fname = EEG_Directory + '\\sub-' + IDs + '.set') #read the EEG file that was renamed earlier in format ID.set\n","      raw = segment_channels(raw)\n","      raw = mne.channels.combine_channels(raw, groups, method = 'median')  #channel averaging\n","      report = computeFOOOF(raw) #FOOOF object to break apart and save in pandas df\n","\n","\n","\n","      ## Saving results to Lists to be made into data frame ##\n","\n","      #from CSV\n","\n","      ProcessedDataDict['ID'].append(IDs)\n","      ProcessedDataDict['Age'].append(phenoDF.loc[IDs,'Age'])\n","      ProcessedDataDict['Sex'].append(phenoDF.loc[IDs,'Sex'])\n","      \n","      #from FOOOF\n","      ProcessedDataDict['Aper_offset'].append(fm.aperiodic_params_[0])\n","      ProcessedDataDict['Aper_exp'].append(fm.aperiodic_params_[-1])\n","      ProcessedDataDict['Variance'].append(fm.r_squared_)\n","      ProcessedDataDict['Error'].append(fm.error_)\n","\n","      PeakNum = 0 \n","      for peak in fm.peak_params_:  #appends the IDs and peak parameters into the lists\n","        ProcessedPeaksDataDict['ID'].append(IDs)\n","        ProcessedPeaksDataDict['Peak_Number'].append(PeakNum)\n","        ProcessedPeaksDataDict['CF'].append(peak[0])\n","        ProcessedPeaksDataDict['PW'].append(peak[1])\n","        ProcessedPeaksDataDict['BW'].append(peak[2])\n","        PeakNum +=1\n","    except FileNotFoundError:\n","      failedIDs.append(IDs)\n","      continue\n","    except Exception as e:\n","      errorLog = (IDs, e)\n","      otherError.append(errorLog)\n","  else:\n","    redundantIDs.append(IDs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ProcessedPeaksDataDict['Age'] = []\n","ProcessedPeaksDataDict['Sex'] = []\n","for uniqueID in ProcessedPeaksDataDict['ID']:\n","    ProcessedPeaksDataDict['Age'].append(phenoDF.loc[uniqueID,'Age'])\n","    ProcessedPeaksDataDict['Sex'].append(phenoDF.loc[uniqueID,'Sex'])\n","print(len(ProcessedPeaksDataDict['Age']))\n","print(len(ProcessedPeaksDataDict['Sex']))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["processedDF = pd.DataFrame(ProcessedDataDict)\n","processedDF.to_csv('ProcessedAperData.csv', index = False)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"NKrJJ_jFlQaF"},"outputs":[],"source":["\n","#multilevel data frame for peaks\n","ProcessedPeaksDF = pd.DataFrame(ProcessedPeaksDataDict)\n","ProcessedPeaksDF.sort_values(['ID', 'Peak_Number']).set_index(['ID', 'Peak_Number'])\n","ProcessedPeaksDF.to_csv('ProcessedPerData.csv', index = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **The Following Section is to Run Null Hyphothesis Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd {EEG_Results_Directory}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["aperDF = pd.read_csv('ProcessedAperData.csv')\n","aperDF = aperDF.set_index('ID')\n","\n","perDF = pd.read_csv('ProcessedPerData.csv')\n","perDF = perDF.set_index('ID')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## *Data Frame for test results*"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [(Pearson Correlation, r), (Pearson Correlation, Pearson P), (Chi-squared, df), (Chi-squared, X²), (Chi-squared, Chi-squared P)]\n","Index: []\n"]}],"source":["Test = [] #format 'independent var name v dependent var name'\n","PearsonR_correlationCoefficient = []\n","PearsonR_pValue = []\n","\n","chiSquared_degreesOfFreedom = []\n","chiSquared_correlationCoefficient = []\n","chiSquared_pValue = []\n","\n","\n","\n","index_values = pd.MultiIndex.from_arrays([Test], names=['Test'])\n","\n","\n","df_pearson = pd.DataFrame(data={\n","    'r': PearsonR_correlationCoefficient,\n","    'Pearson P': PearsonR_pValue\n","})\n","\n","\n","df_chi_squared = pd.DataFrame(data={\n","    'df': chiSquared_degreesOfFreedom,\n","    'X²': chiSquared_correlationCoefficient,\n","    'Chi-squared P': chiSquared_pValue\n","})\n","\n","# Combine the DataFrames into the MultiIndex DataFrame\n","NullHypothesisTestingDF = pd.concat([df_pearson, df_chi_squared], axis=1,\n","                                    keys=['Pearson Correlation', 'Chi-squared'])\n","\n","# Assign the MultiIndex to the DataFrame\n","NullHypothesisTestingDF.index = index_values\n","\n","\n","print(NullHypothesisTestingDF)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## *The following Chi - Squared tests treat age in groups 5 - 8 (research is 5-8 so groups of age 5 are lumped into this 6-8), 9 - 12, and 13 - 22 (research is 13 - late 20s and oldest subject is 22), rounding age to the nearest year. The continuous test uses a pearson test to check for correlation for the null hypothesis, treating age as continuous instead of groups like the chi - Squared tests* "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" *Test for Age V. Offset |      (H0) Offset is independent of Age      |      (H1) Offset varies based on an individual's Age*"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["#get age and offset \n","DependentVariable = []\n","IndependentVariable = []\n","for ID, row in aperDF.iterrows():\n","    DependentVariable.append(aperDF.loc[ID, 'Age'])\n","    IndependentVariable.append(aperDF.loc[ID, 'Aper_offset'])\n","    "]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["#sort the data into age groups\n","\n","youngest = []\n","middle = []\n","oldest = []\n","\n","for ID, row in aperDF.iterrows():\n","        if (5 <= round(aperDF.loc[ID, 'Age']) <= 8):\n","            youngest.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (9 <= round(aperDF.loc[ID, 'Age']) <= 12):\n","            middle.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (13 <= round(aperDF.loc[ID, 'Age']) <= 22):\n","            oldest.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        else:   \n","            raise Exception('Participant Age is outside of expected range')"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        13 - 22  6 - 8  9 - 12 \n","-14.42      0.0    1.0      0.0\n","-13.99      1.0    0.0      0.0\n","-13.90      0.0    0.0      1.0\n","-13.30      0.0    1.0      0.0\n","-13.21      0.0    0.0      1.0\n","...         ...    ...      ...\n","-7.93       1.0    0.0      0.0\n","-7.67       1.0    0.0      0.0\n","-7.63       0.0    0.0      1.0\n","-7.56       0.0    1.0      0.0\n","-6.97       0.0    1.0      0.0\n","\n","[353 rows x 3 columns]\n"]}],"source":["#Count the values and create contingency table\n","\n","youngestFrequencies = Counter(youngest)\n","middleFrequencies = Counter(middle)\n","oldestFrequencies = Counter(oldest)\n","\n","chiYoungestDF = pd.DataFrame.from_dict(youngestFrequencies, orient='index', columns=['6 - 8'])\n","chiMiddleDF = pd.DataFrame.from_dict(middleFrequencies, orient='index', columns=['9 - 12 '])\n","chiOldestDF = pd.DataFrame.from_dict(oldestFrequencies, orient='index', columns=['13 - 22'])\n","\n","chi2_contingency_table = chiOldestDF.combine_first(chiYoungestDF.combine_first(chiMiddleDF))\n","chi2_contingency_table = chi2_contingency_table.fillna(0)\n","print(chi2_contingency_table)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        13 - 22  6 - 8  9 - 12 \n","-14.42      0.0    1.0      0.0\n","-14.41      0.0    0.0      0.0\n","-14.40      0.0    0.0      0.0\n","-14.39      0.0    0.0      0.0\n","-14.38      0.0    0.0      0.0\n","...         ...    ...      ...\n","-7.01       0.0    0.0      0.0\n","-7.00       0.0    0.0      0.0\n","-6.99       0.0    0.0      0.0\n","-6.98       0.0    0.0      0.0\n","-6.97       0.0    1.0      0.0\n","\n","[746 rows x 3 columns]\n"]}],"source":["#Fill in missing values for men and women so that degrees of freedom and expected values are correctly calculated\n","index_values = np.arange(-14.42, -6.96, 0.01).round(2)\n","\n","# Filter out the existing index values\n","index_values = [x for x in index_values if x not in chi2_contingency_table.index]\n","\n","# Create new rows with missing index values and fill with zeros\n","new_rows = pd.DataFrame(0, index = index_values, columns = chi2_contingency_table.columns)\n","\n","chi2_contingency_table = pd.concat([chi2_contingency_table, new_rows])\n","\n","chi2_contingency_table.sort_index(inplace=True)\n","\n","print(chi2_contingency_table)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["chi2_stat, chi2_p, chi2_dof, chi2_expected = scipy.stats.chi2_contingency(chi2_contingency_table.values)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-0.36567123547262415\n","\n","3.616996774821717e-93\n"]}],"source":["#perform the pearson r test (treats age as continuous)\n","\n","correlationCoef, pearsonR_p = scipy.stats.pearsonr(DependentVariable, IndependentVariable)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["NullHypothesisTestingDF.loc['Age v Offset', ('Pearson Correlation', 'r')]= correlationCoef\n","NullHypothesisTestingDF.loc['Age v Offset', ('Pearson Correlation', 'Pearson P')] = pearsonR_p\n","\n","NullHypothesisTestingDF.loc['Age v Offset', ('Chi-squared', 'df')] = chi2_dof\n","NullHypothesisTestingDF.loc['Age v Offset', ('Chi-squared', 'X²')] = chi2_stat\n","NullHypothesisTestingDF.loc['Age v Offset', ('Chi-squared', 'Chi-squared P')] = chi2_p"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">Pearson Correlation</th>\n","      <th colspan=\"3\" halign=\"left\">Chi-squared</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>r</th>\n","      <th>Pearson P</th>\n","      <th>df</th>\n","      <th>X²</th>\n","      <th>Chi-squared P</th>\n","    </tr>\n","    <tr>\n","      <th>Test</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Age v Offset</th>\n","      <td>-0.365671</td>\n","      <td>3.616997e-93</td>\n","      <td>704</td>\n","      <td>1181.897534</td>\n","      <td>8.313125e-27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Pearson Correlation               Chi-squared               \\\n","                               r     Pearson P          df           X²   \n","Test                                                                      \n","Age v Offset           -0.365671  3.616997e-93         704  1181.897534   \n","\n","                            \n","             Chi-squared P  \n","Test                        \n","Age v Offset  8.313125e-27  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["NullHypothesisTestingDF"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" *Test for Age V. Aperiodic Exponent |      (H0) Exponent is independent of Age      |      (H1) Exponent varies based on an individual's Age*"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["DependentVariable = []\n","IndependentVariable = []\n","for ID, row in aperDF.iterrows():\n","    DependentVariable.append(aperDF.loc[ID, 'Age'])\n","    IndependentVariable.append(aperDF.loc[ID, 'Aper_exp'])"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["#sort the data into age groups\n","\n","youngest = []\n","middle = []\n","oldest = []\n","\n","for ID, row in aperDF.iterrows():\n","        if (5 <= round(aperDF.loc[ID, 'Age']) <= 8):\n","            youngest.append(round(aperDF.loc[ID, 'Aper_exp'], 2))\n","        elif (9 <= round(aperDF.loc[ID, 'Age']) <= 12):\n","            middle.append(round(aperDF.loc[ID, 'Aper_exp'], 2))\n","        elif (13 <= round(aperDF.loc[ID, 'Age']) <= 22):\n","            oldest.append(round(aperDF.loc[ID, 'Aper_exp'], 2))\n","        else:   \n","            raise Exception('Participant Age is outside of expected range')\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["#Count the values and create contingency table\n","\n","youngestFrequencies = Counter(youngest)\n","middleFrequencies = Counter(middle)\n","oldestFrequencies = Counter(oldest)\n","\n","chiYoungestDF = pd.DataFrame.from_dict(youngestFrequencies, orient='index', columns=['6 - 8'])\n","chiMiddleDF = pd.DataFrame.from_dict(middleFrequencies, orient='index', columns=['9 - 12 '])\n","chiOldestDF = pd.DataFrame.from_dict(oldestFrequencies, orient='index', columns=['13 - 22'])\n","\n","chi2_contingency_table = chiOldestDF.combine_first(chiYoungestDF.combine_first(chiMiddleDF))\n","chi2_contingency_table = chi2_contingency_table.fillna(0)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["       13 - 22  6 - 8  9 - 12 \n","-1.88      1.0    0.0      0.0\n","-1.87      0.0    0.0      0.0\n","-1.86      0.0    0.0      0.0\n","-1.85      0.0    0.0      0.0\n","-1.84      0.0    0.0      0.0\n","...        ...    ...      ...\n"," 3.57      0.0    0.0      0.0\n"," 3.58      0.0    0.0      0.0\n"," 3.59      0.0    0.0      0.0\n"," 3.60      0.0    0.0      0.0\n"," 3.61      0.0    1.0      0.0\n","\n","[550 rows x 3 columns]\n"]}],"source":["#Fill in missing values for men and women so that degrees of freedom and expected values are correctly calculated\n","index_values = np.arange(-1.88, 3.62, 0.01).round(2)\n","\n","# Filter out the existing index values\n","index_values = [x for x in index_values if x not in chi2_contingency_table.index]\n","\n","# Create new rows with missing index values and fill with zeros\n","new_rows = pd.DataFrame(0, index = index_values, columns = chi2_contingency_table.columns)\n","\n","chi2_contingency_table = pd.concat([chi2_contingency_table, new_rows])\n","\n","chi2_contingency_table.sort_index(inplace=True)\n","\n","print(chi2_contingency_table)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["chi2_stat, chi2_p, chi2_dof, chi2_expected = scipy.stats.chi2_contingency(chi2_contingency_table.values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP6z7wowje593Xg+0JvU0Ec","mount_file_id":"1jGWUWMrA1-dfCUv0UVdZl13XC1Kj8avM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20848,"status":"ok","timestamp":1686962803440,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"2Urp3jOQIPZU","outputId":"019773e5-4fdb-4b05-b729-f1b43cbfd23d"},"outputs":[],"source":["%pip install mne\n","%pip install matplotlib\n","%pip install pymatreader\n","%pip install scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6950,"status":"ok","timestamp":1686962815662,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"I8IYSjLfnE2a","outputId":"18360fe9-feca-4ab9-c8e8-34d88c241d40"},"outputs":[],"source":["%pip install FOOOF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5530,"status":"ok","timestamp":1686962821190,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"SdqqDQ_znLgQ","outputId":"2624c960-fcc3-441d-9c1c-40599a82760a"},"outputs":[],"source":["%pip install neurodsp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install python-dotenv"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"FuEv2adNIdH6"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv()\n","\n","import numpy as np\n","import matplotlib\n","import mne\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# the following import is required for matplotlib < 3.2:\n","from mpl_toolkits.mplot3d import Axes3D  # noqa\n","\n","from neurodsp.spectral import compute_spectrum, trim_spectrum\n","\n","\n","# Import NeuroDSP plotting functions\n","from neurodsp.plts import (plot_time_series, plot_power_spectra, plot_bursts, plot_lagged_coherence)\n","\n","from fooof import FOOOF\n","import os\n","import pandas as pd\n","import csv\n","\n","import scipy\n","from scipy import stats\n","from collections import Counter"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["load_dotenv('PipelineVariables.env')\n","EEG_Directory=os.getenv('EEG_Directory')\n","EEG_Results_Directory=os.getenv('EEG_Results_Directory')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ijhj11fh-8oL"},"source":["# **The Following functions are functions for pre-processing the data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd {EEG_Directory}"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1T-IXK1cJKht"},"outputs":[],"source":["def segment_channels(raw): ## segments the data into desired channels\n","  channels_to_keep = ['E1', 'E2', 'E3', 'E4', 'E8', 'E9', 'E10', 'E15', 'E16', 'E18', 'E22', 'E23', 'E24', 'E25', 'E26', 'E27', 'E32', 'E33', 'E122', 'E123', 'E124']\n","  return raw.pick_channels(channels_to_keep)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"M_3CR4fk0FmY"},"outputs":[],"source":["def avgChannels(raw): ## averages channels into one evoked object of the data for the frontal lobe\n","  events = mne.find_events(raw, stim_channel = None)\n","  epochs = mne.Epochs(raw, events, event_id=None, tmin=0, tmax=10)\n","  evoked = epochs.average()\n","  return evoked"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Jl5Gbjxbzw_L"},"outputs":[],"source":["def computeFOOOF(raw):  ## FOOOF computations\n","  data, times = raw[:,:]\n","  freqs, powers = compute_spectrum(data[0], fs, method='welch', avg_type='median')\n","  freqs, powers = trim_spectrum(freqs, powers, [3, 28])\n","  return fm.report(freqs, powers, [3,28])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BuJuMwtmyytb"},"source":["# **These blocks create necessary global variables for preprocessing, set our working directory, creating the FOOOF report, renaming files, and creating the PANDAS dataframe**"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1rESsSvY6m6u"},"outputs":[],"source":["\n","groups=dict(frontal = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n","fs = 250"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CAJIMdagnj0F"},"outputs":[],"source":["#PANDAS Lists to be appended then made into Data frame\n","PersonalID = []\n","age = []\n","sex =[]\n","\n","Aper_offset = []\n","Aper_exp = []\n","variance = []\n","error = []\n","\n","ProcessedDataDict = {'ID': PersonalID, 'Age': age, 'Sex': sex,\n","'Aper_offset': Aper_offset, 'Aper_exp': Aper_exp, 'Variance': variance, 'Error': error}\n","\n","PeakID = []\n","PeakIndex = []\n","CenterFrequency = []\n","PeakWidth = []\n","BandWidth = []\n","\n","ProcessedPeaksDataDict = {'ID': PeakID, 'Age': age, 'Sex': sex, 'Peak_Number': PeakIndex , 'CF': CenterFrequency, 'PW': PeakWidth, 'BW': BandWidth}\n","\n","failedIDs = []\n","redundantIDs = []\n","otherError = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686962824809,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"vvwYeeJmtoZJ","outputId":"65e8076f-ac79-44db-dae8-f3317533bb06"},"outputs":[],"source":["%cd {EEG_Directory}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kCsP7CFhW4P1"},"source":["Completed so don't run once renamed"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3ErpbYdE9RMf"},"outputs":[],"source":["\n","# for filename in os.listdir():\n","#   if filename.endswith('.fdt'):\n","#     os.rename(filename, filename[::-1][22::][::-1] + '.fdt')  #renames the files\n","#   elif filename.endswith('.set'):\n","#     os.rename(filename, filename[::-1][22::][::-1] + '.set')\n","# print('successfully completed')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SAQwx0UzydDS"},"source":["# **Loop for preprocessing the files, creating FOOOF report, and saving the report to pandas.**"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"XNCcC72qIEs1"},"outputs":[],"source":["phenoDF = pd.read_csv('CorrectPhenotypesRaw.csv')  #phenotpypic data frame\n","phenoDF = phenoDF.set_index('EID')\n","\n","fm = FOOOF()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XhzTHOMIN_nb"},"source":["Cell runs the analysis and saves values to be made into data frame"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JG2wEwcU-oJedBVUSPrkOaztNiZb9Lt_"},"executionInfo":{"elapsed":3862581,"status":"error","timestamp":1686968287161,"user":{"displayName":"Ishaan Buddharaju","userId":"14720957963732667520"},"user_tz":300},"id":"taTCR2RYlIhm","outputId":"855740aa-01a7-4d55-a82c-ca2f2fbd3e40"},"outputs":[],"source":["for IDs, row in phenoDF.iterrows():\n","  if IDs not in PersonalID:\n","    try:\n","      raw = mne.io.read_raw_eeglab(input_fname = EEG_Directory + '\\sub-' + IDs + '.set') #read the EEG file that was renamed earlier in format ID.set\n","      raw = segment_channels(raw)\n","      raw = mne.channels.combine_channels(raw, groups, method = 'median')  #channel averaging\n","      report = computeFOOOF(raw) #FOOOF object to break apart and save in pandas df\n","\n","\n","\n","      ## Saving results to Lists to be made into data frame ##\n","\n","      #from CSV\n","\n","      ProcessedDataDict['ID'].append(IDs)\n","      ProcessedDataDict['Age'].append(phenoDF.loc[IDs,'Age'])\n","      ProcessedDataDict['Sex'].append(phenoDF.loc[IDs,'Sex'])\n","      \n","      #from FOOOF\n","      ProcessedDataDict['Aper_offset'].append(fm.aperiodic_params_[0])\n","      ProcessedDataDict['Aper_exp'].append(fm.aperiodic_params_[-1])\n","      ProcessedDataDict['Variance'].append(fm.r_squared_)\n","      ProcessedDataDict['Error'].append(fm.error_)\n","\n","      PeakNum = 0 \n","      for peak in fm.peak_params_:  #appends the IDs and peak parameters into the lists\n","        ProcessedPeaksDataDict['ID'].append(IDs)\n","        ProcessedPeaksDataDict['Peak_Number'].append(PeakNum)\n","        ProcessedPeaksDataDict['CF'].append(peak[0])\n","        ProcessedPeaksDataDict['PW'].append(peak[1])\n","        ProcessedPeaksDataDict['BW'].append(peak[2])\n","        PeakNum +=1\n","    except FileNotFoundError:\n","      failedIDs.append(IDs)\n","      continue\n","    except Exception as e:\n","      errorLog = (IDs, e)\n","      otherError.append(errorLog)\n","  else:\n","    redundantIDs.append(IDs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ProcessedPeaksDataDict['Age'] = []\n","ProcessedPeaksDataDict['Sex'] = []\n","for uniqueID in ProcessedPeaksDataDict['ID']:\n","    ProcessedPeaksDataDict['Age'].append(phenoDF.loc[uniqueID,'Age'])\n","    ProcessedPeaksDataDict['Sex'].append(phenoDF.loc[uniqueID,'Sex'])\n","print(len(ProcessedPeaksDataDict['Age']))\n","print(len(ProcessedPeaksDataDict['Sex']))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["processedDF = pd.DataFrame(ProcessedDataDict)\n","processedDF.to_csv('ProcessedAperData.csv', index = False)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"NKrJJ_jFlQaF"},"outputs":[],"source":["\n","#multilevel data frame for peaks\n","ProcessedPeaksDF = pd.DataFrame(ProcessedPeaksDataDict)\n","ProcessedPeaksDF.sort_values(['ID', 'Peak_Number']).set_index(['ID', 'Peak_Number'])\n","ProcessedPeaksDF.to_csv('ProcessedPerData.csv', index = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **The Following Section is to Run Null Hyphothesis Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd {EEG_Results_Directory}"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["aperDF = pd.read_csv('ProcessedAperData.csv')\n","aperDF = aperDF.set_index('ID')\n","\n","perDF = pd.read_csv('ProcessedPerData.csv')\n","perDF = perDF.set_index('ID')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## *Data Frame for test results*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Test = [] #format 'independent var name v dependent var name'\n","TestSex = [] #The associated sex for the test (each test will have both a M and F test)\n","PearsonR_correlationCoefficient = []\n","PearsonR_pValue = []\n","\n","chiSquared_degreesOfFreedom = []\n","chiSquared_SampleSize = []\n","chiSquared_correlationCoefficient = []\n","chiSquared_pValue = []\n","\n","\n","\n","index_values = pd.MultiIndex.from_arrays([Test, TestSex], names=['Test', 'Sex'])\n","\n","\n","df_pearson = pd.DataFrame(data={\n","    'r': PearsonR_correlationCoefficient,\n","    'Pearson P': PearsonR_pValue\n","})\n","\n","\n","df_chi_squared = pd.DataFrame(data={\n","    'df': chiSquared_degreesOfFreedom,\n","    'N': chiSquared_SampleSize,\n","    'X²': chiSquared_correlationCoefficient,\n","    'Chi-squared P': chiSquared_pValue\n","})\n","\n","# Combine the DataFrames into the MultiIndex DataFrame\n","NullHypothesisTestingDF = pd.concat([df_pearson, df_chi_squared], axis=1,\n","                                    keys=['Pearson Correlation', 'Chi-squared'])\n","\n","# Assign the MultiIndex to the DataFrame\n","NullHypothesisTestingDF.index = index_values\n","\n","\n","print(NullHypothesisTestingDF)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## *The following Chi - Squared tests treat age in groups 5 - 8 (research is 5-8 so groups of age 5 are lumped into this 6-8), 9 - 12, and 13 - 22 (research is 13 - late 20s and oldest subject is 22), rounding age to the nearest year and seperating the tests for male v female then testing the dependent variable against sex to confirm prior research. The continuous test uses a pearson test to check for correlation for the null hypothesis, treating age as continuous instead of groups like the chi - Squared tests* "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" *Test for Age V. Offset Female & Male      |      (H0) Offset is independent of Age      |      (H1) Offset varies based on an individual's Age*"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["#Run for 0s (Women) and 1s (Male)   to get the Age and Aperiodic Offset sorted by Men and Women\n","DependentVariable_Women = []\n","IndependentVariable_Women = []\n","\n","DependentVariable_Men = []\n","IndependentVariable_Men = []\n","\n","for ID, row in aperDF.iterrows():\n","    if aperDF.loc[ID, 'Sex'] == 0.0:\n","        DependentVariable_Women.append(aperDF.loc[ID, 'Age'])\n","        IndependentVariable_Women.append(aperDF.loc[ID, 'Aper_offset'])\n","    elif aperDF.loc[ID, 'Sex'] == 1.0:\n","        DependentVariable_Men.append(aperDF.loc[ID, 'Age'])\n","        IndependentVariable_Men.append(aperDF.loc[ID, 'Aper_offset'])\n","    else:\n","        raise\n","\n","    if len(DependentVariable_Women) != len(IndependentVariable_Women):   #Just to be extra safe in case a loc raises an error if you use this code for a different use case\n","        raise Exception('Check again, the variables are not the same length')\n","\n","    if len(DependentVariable_Men) != len(IndependentVariable_Men):       #Just to be extra safe in case a loc raises an error if you use this code for a different use case\n","        raise Exception('Check again, the variables are not the same length')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#sort the data into groups for both men and women (see above group explanation) for the chi squared test \n","\n","youngestOffsets_Women = []\n","middleOffsets_Women = []\n","highestOffsets_Women = []\n","\n","youngestOffsets_Men = []\n","middleOffsets_Men = []\n","highestOffsets_Men = []\n","for ID, row in aperDF.iterrows():\n","    if aperDF.loc[ID, 'Sex'] == 0.0:\n","        if (5 <= round(aperDF.loc[ID, 'Age']) <= 8):\n","            youngestOffsets_Women.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (9 <= round(aperDF.loc[ID, 'Age']) <= 12):\n","            middleOffsets_Women.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (13 <= round(aperDF.loc[ID, 'Age']) <= 22):\n","            highestOffsets_Women.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        else:   \n","            raise Exception('Participant Age is outside of expected range')\n","    elif aperDF.loc[ID, 'Sex'] == 1.0:\n","        if (5 <= round(aperDF.loc[ID, 'Age']) <= 8):\n","            youngestOffsets_Men.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (9 <= round(aperDF.loc[ID, 'Age']) <= 12):\n","            middleOffsets_Men.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        elif (13 <= round(aperDF.loc[ID, 'Age']) <= 22):\n","            highestOffsets_Men.append(round(aperDF.loc[ID, 'Aper_offset'], 2))\n","        else:   \n","            raise Exception('Participant Age is outside of expected range')\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        13 - 22  6 - 8  9 - 12 \n","-14.42      0.0    1.0      0.0\n","-13.21      0.0    0.0      1.0\n","-13.11      0.0    1.0      0.0\n","-13.10      1.0    0.0      0.0\n","-13.09      0.0    1.0      0.0\n","...         ...    ...      ...\n","-8.24       0.0    0.0      1.0\n","-8.13       0.0    1.0      0.0\n","-7.67       1.0    0.0      0.0\n","-7.56       0.0    1.0      0.0\n","-6.97       0.0    1.0      0.0\n","\n","[307 rows x 3 columns]\n"]}],"source":["#Count the values and create contingency table for women\n","\n","youngestFrequencies_Women = Counter(youngestOffsets_Women)\n","middleFrequencies_Women = Counter(middleOffsets_Women)\n","highestFrequencies_Women = Counter(highestOffsets_Women)\n","\n","chiYoungestDF_Women = pd.DataFrame.from_dict(youngestFrequencies_Women, orient='index', columns=['6 - 8'])\n","chiMiddleDF_Women = pd.DataFrame.from_dict(middleFrequencies_Women, orient='index', columns=['9 - 12 '])\n","chiHighestDF_Women = pd.DataFrame.from_dict(highestFrequencies_Women, orient='index', columns=['13 - 22'])\n","\n","chiSquared_DF_Women = chiMiddleDF_Women.combine_first(chiHighestDF_Women.combine_first(chiYoungestDF_Women))\n","chiSquared_DF_Women = chiSquared_DF_Women.fillna(0)\n","print(chiSquared_DF_Women)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["        13 - 22  6 - 8  9 - 12 \n","-13.99      1.0    0.0      0.0\n","-13.90      0.0    0.0      1.0\n","-13.30      0.0    1.0      0.0\n","-13.09      1.0    0.0      0.0\n","-13.08      1.0    0.0      0.0\n","...         ...    ...      ...\n","-8.45       0.0    1.0      0.0\n","-8.25       0.0    1.0      0.0\n","-8.17       1.0    0.0      0.0\n","-7.93       1.0    0.0      0.0\n","-7.63       0.0    0.0      1.0\n","\n","[279 rows x 3 columns]\n"]}],"source":["#Count the values and create contingency table for men\n","\n","youngestFrequencies_Men = Counter(youngestOffsets_Men)\n","middleFrequencies_Men = Counter(middleOffsets_Men)\n","highestFrequencies_Men = Counter(highestOffsets_Men)\n","\n","chiYoungestDF_Men = pd.DataFrame.from_dict(youngestFrequencies_Men, orient='index', columns=['6 - 8'])\n","chiMiddleDF_Men = pd.DataFrame.from_dict(middleFrequencies_Men, orient='index', columns=['9 - 12 '])\n","chiHighestDF_Men = pd.DataFrame.from_dict(highestFrequencies_Men, orient='index', columns=['13 - 22'])\n","\n","chiSquared_DF_Men = chiMiddleDF_Men.combine_first(chiHighestDF_Men.combine_first(chiYoungestDF_Men))\n","chiSquared_DF_Men = chiSquared_DF_Men.fillna(0)\n","print(chiSquared_DF_Men)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#Fill in missing values for men and women so that degrees of freedom and expected values are correctly calculated\n","index_values_Women = np.arange(-14.5, -6.5, 0.5).round(1)\n","index_values_Men = np.arange(-14.42, -6.96, 0.01).round(2)\n","# Filter out the existing index values\n","new_index_values_women = [x for x in index_values_Women if x not in chiSquared_DF_Women.index]\n","new_index_values_men = [x for x in index_values_Men if x not in chiSquared_DF_Men.index]\n","\n","# Create new rows with missing index values and fill with zeros\n","new_rows_women = pd.DataFrame(0, index=new_index_values_women, columns=chiSquared_DF_Women.columns)\n","new_rows_men = pd.DataFrame(0, index=new_index_values_men, columns=chiSquared_DF_Men.columns)\n","\n","chiSquared_DF_Women = pd.concat([chiSquared_DF_Women, new_rows_women])\n","chiSquared_DF_Men = pd.concat([chiSquared_DF_Men, new_rows_men])\n","\n","chiSquared_DF_Women.sort_index(inplace=True)\n","chiSquared_DF_Men.sort_index(inplace=True)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["#Building the lists for chi squared excepted values and actual values\n","expectedValues_chi_Women = []\n","observedValues_chi_Women = []\n","\n","observedValues_chi_Men = []\n","expectedValues_chi_Men = []\n","\n","#sum totals to use as constants to calc expected values (both values are constant but just for consitencies sake they are treated seperately)\n","WomenDFtotal = chiSquared_DF_Women.sum().sum()\n","MenDFtotal = chiSquared_DF_Men.sum().sum()\n","\n","#degrees of freedom for the chi test (calculated as [num rows - 1][num col - 1]) (both values are constant but just for consitencies sake they are treated seperately)\n","chiDDOF_Women = (len(chiSquared_DF_Women) - 1)*(len(chiSquared_DF_Women.columns) - 1) #same for both\n","chiDDOF_Men = (len(chiSquared_DF_Men) - 1)*(len(chiSquared_DF_Men.columns) - 1)\n","\n","for column in chiSquared_DF_Women:  #expected and observed values for women in age v offset\n","    for aperOffset_index, row in chiSquared_DF_Women.iterrows():  #df is indexed by the offset so get offset and column for to get observed values\n","        if row.sum() != 0: #omit cases of row tot equal zero causing f_exp to be zero (works because ddof is constant)\n","            observedValues_chi_Women.append(chiSquared_DF_Women.loc[aperOffset_index, column])\n","            expectedValues_chi_Women.append(row.sum() * chiSquared_DF_Women[column].sum()/WomenDFtotal) #expected value formula is row total * column total / total\n","\n","            \n","for column in chiSquared_DF_Men:  #expected and observed values for Men in age v offset\n","    for aperOffset_index, row in chiSquared_DF_Men.iterrows():  #df is indexed by the offset so get offset and column for to get observed values\n","        if row.sum() != 0: #omit cases of row tot equal zero causing f_exp to be zero (works because ddof is constant)\n","            observedValues_chi_Men.append(chiSquared_DF_Men.loc[aperOffset_index, column])\n","            expectedValues_chi_Men.append((row.sum() * chiSquared_DF_Men[column].sum())/MenDFtotal) #expected value formula is row total * column total / total"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["846.9660236851139|6.073247654431732e-56\n","\n","712.7748947008497|nan\n"]}],"source":["# Perform chi-squared test on chiSquared_DF_Women \n","chi2_stat_Women, chi2_pValue_Women = scipy.stats.chisquare(f_obs= observedValues_chi_Women, f_exp=expectedValues_chi_Women, ddof=chiDDOF_Women)\n","\n","# Perform chi-squared test on chiSquared_DF_Men\n","chi2_stat_Men, chi2_pValue_Men = scipy.stats.chisquare(f_obs= observedValues_chi_Men, f_exp=expectedValues_chi_Men, ddof= chiDDOF_Men)\n","\n","print(str(chi2_stat_Women) + \"|\" + str(chi2_pValue_Women) + \"\\n\\n\" + str(chi2_stat_Men) + \"|\" + str(chi2_pValue_Men))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-0.3595585117799993|1.0998505937476708e-58\n","\n","-0.3752138928653138|5.601559899917795e-36\n"]}],"source":["#perform the pearson r test (treats age as continuous)\n","\n","correlationCoef_Women, pearsonR_p_Women = scipy.stats.pearsonr(DependentVariable_Women, IndependentVariable_Women)\n","\n","correlationCoef_Men, pearsonR_p_Men = scipy.stats.pearsonr(DependentVariable_Men, IndependentVariable_Men)\n","\n","print(str(correlationCoef_Women) + \"|\" + str(pearsonR_p_Women) + \"\\n\\n\" + str(correlationCoef_Men) + \"|\" + str(pearsonR_p_Men))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP6z7wowje593Xg+0JvU0Ec","mount_file_id":"1jGWUWMrA1-dfCUv0UVdZl13XC1Kj8avM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
main
